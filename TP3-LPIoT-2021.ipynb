{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import *\n",
    "from numpy import *\n",
    "from numpy.linalg import * \n",
    "from matplotlib.pylab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 1 : bac à sable pour les données \"jouet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2 : programmation de l'ACP (suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On reprend les données du fichier `demographie.xls` qui contient des statistiques d'une étude de 1987 concernant 166 pays.\n",
    "Les statistiques des pays correspondent aux 15 variables (1 qualitative, 14 quantitatives) suivantes :\n",
    "- COUNTRY : nom du pays\n",
    "- POP87 : population en 1987\n",
    "- NAT : taux de natalité\n",
    "- MORT : taux de mortalité\n",
    "- ACCR : taux d'accroissement de la population\n",
    "- POP00 : population prévue pour 2000\n",
    "- POP20 : population prévue pour 2020\n",
    "- MORTI : taux de mortalité infantile\n",
    "- FERTI : taux de fertilité\n",
    "- AGE15 : proportion de la population  de moins de 15 ans\n",
    "- AGE65 : proportion de la population  de plus de 65 ans\n",
    "- ESPER : espérance de vie\n",
    "- URBA : taux d'urbanisation\n",
    "- PNB : produit national brut\n",
    "- CONTI : continent (1=Afrique, 2=Asie, 3=Amérique, 4=Europe, 5=Océanie)\n",
    "\n",
    "On définit les arrays suivants:\n",
    "- `pays` :  les noms des pays\n",
    "- `continent` :  les numéros des continents\n",
    "- `data` : les autres variables (qui sont quantitatives et donc adaptées à une ACP)\n",
    "- `labels`: les noms des variables contenues dans `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =read_excel('demographie.xls')\n",
    "pays = df['COUNTRY'].values\n",
    "continent = df['CONTI'].values\n",
    "data = df[['POP87','NAT','MORT','ACCR','POP00','POP20','MORTI','FERTI','AGE15','AGE65','ESPER','URBA','PNB']].values\n",
    "labels=['87','NAT','MORT','ACCR','00','20','MORTI','FERTI','-15','+65','ESPER','URBA','PNB']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 0.** On a recopié ci-dessous (une version de) la fonction `acp` écrite à la séance précédente. Commentez chaque ligne de commande en expliquant son rôle puis testez la fonction `acp` sur les données de démographie `data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(M):\n",
    "    n,p=shape(M)\n",
    "    Z=zeros((n,p))\n",
    "    for j in range(p):\n",
    "        Z[:,j]=(M[:,j]-mean(M[:,j]))/std(M[:,j])\n",
    "    return Z\n",
    "def acp(M):\n",
    "    n,p=shape(M) \n",
    "    Z=normalise(M)\n",
    "    R= 1/n*dot(Z.T,Z)\n",
    "    val0, P0 = eigh(R) \n",
    "    val = sort(val0)[::-1] \n",
    "    index = argsort(val0)[::-1] \n",
    "    P=zeros((p,p))\n",
    "    for j in range(p):\n",
    "        P[:,j]=P0[:,index[j]]\n",
    "    C=dot(Z,P)\n",
    "    return val, P, C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Quelle est la proportion de variance expliquée par les deux premières composantes principales? par les trois premières?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** À partir de `data`, représentez les points-individus dans le plan principal en nommant les axes (`CP 1`, `CP 2`).  Commentez le graphique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3** Créez une fonction `cercle_corr` qui prend en entrée un tableau de données et les noms des variables de départ puis affiche le cercle des corrélations entre les variables centrées réduites de départ et les deux premières composantes principales. Il faudra que les noms des variables apparaissent sur le graphique.\n",
    "Vous testerez votre fonction avec `data` et `labels`, et commenterez les résultats obtenus.\n",
    "\n",
    "*Pour que le cercle ne soit pas aplati, il est préférable de fixer la taille de la figure de telle sorte qu'elle s'inscrive dans un carré, par exemple via la commande `figure(figsize=(10,10))`.*\n",
    "\n",
    "*Pour afficher un \"joli\" cercle, vous pourrez utiliser la suite de commandes :*\n",
    "    \n",
    "`circle1=Circle((0,0),radius=1, color='g', fill=False)`\n",
    "\n",
    "`fig = gcf()`\n",
    "\n",
    "`fig.gca().add_artist(circle1)`\n",
    "\n",
    "`xlim((-1,1)); ylim((-1,1)); grid(True)`\n",
    "    \n",
    "*Pour afficher le nom d'une variable au point de coordonnées `x`,`y`, vous pourrez utiliser:*\n",
    "\n",
    "`annotate('nom_variable', (x,y))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** On enlève à présent les trois variables `POP87`, `POP00`, `POP20`. Recommencez l'ACP et tracez le nouveau cercle des corrélations. Commentez. Quelle est à présent la proportion de variance expliquée par les deux premières composantes principales ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = delete(data,[0,4,5],axis=1)\n",
    "p2=shape(data2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 3 : Reconnaissance faciale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation des images de visages avec la librairie sklearn\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_dataset = fetch_lfw_people(min_faces_per_person=200) # on ne garde que les individus avec au moins 200 images\n",
    "X=lfw_dataset.data # vecteur ligne des niveaux de gris de l'image \n",
    "y=lfw_dataset.target # labels des images\n",
    "noms = lfw_dataset.target_names # noms des personnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous venons d'importer 766 photos, en fait 530 photos de George W Bush, président des Etat-Unis entre 2001 et 2009, et 236 photos de Colin Powell, secrétaire d'État des États-Unis au début de la guerre en Irak. Le but de cet exercice est de construire un algorithme de reconnaissance faciale de ces deux personnages.\n",
    "\n",
    "Chaque photo est encodée par un vecteur ligne de 2914 nombres entre 0 et 255 (8 bits) représentant les niveaux de gris des pixels. Nous avons regroupé les 766 photos dans la matrice $X$ qui est donc de format 766$\\times$2914.\n",
    "Le vecteur $y$ contient les labels des photos : y=1 si c'est une photo de G.W. Bush et y=0 si c'est une photo de C. Powel.\n",
    "\n",
    "Pour afficher les portraits de ces deux personalités, il faut utiliser la fonction `imshow` en prenant soin de redimensionner le vecteur ligne $X[i,:]$ en indiquant la largueur, la hauteur  et l'encodage en noir et blanc avec l'option\n",
    "`cmap=plt.cm.gray`. Voici les premières images du jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=lfw_dataset.images.shape # les dimensions du jeu de données\n",
    "h=dim[1] # hauteur de chaque image en nombre de pixels\n",
    "w=dim[2] # largeur de chaque image en nombre de pixels\n",
    "# on affiche les premières images du jeu de données X, avec les noms correspondants\n",
    "figure(figsize=(20,20)) # taille de la figure\n",
    "for i in range(15):\n",
    "    subplot(5,5,i+1) # sous figures\n",
    "    imshow(X[i,:].reshape((h, w)), cmap=plt.cm.gray) # affichage de chaque figure\n",
    "    title(noms[y[i]]) # noms\n",
    "show()\n",
    "print('Les labels associés aux images affichées ci-dessus sont : ',y[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va à présent séparer le jeu de données aléatoirement en deux. Nous allons entrainer notre algorithme sur les données `X_train`, `y_train` puis le tester sur `X_test`, `y_test`. La variable `test_size` spécifie la proportion de données test que l'on souhaite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # permet de découper les données\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithme du plus proche voisin :**\n",
    "\n",
    "Voici comment va fonctionner l'algorithme de reconnaissance faciale. Chaque image est un point d'un espace de dimension 2914 (nombre de pixels). On va attribuer le label $i$ (0 pour C. Powel, 1 pour G.W. Bush) à une image du jeu de données test `X_test` si l'image la plus proche (au sens de la distance euclidienne)\n",
    "du jeu de données `X_train` a pour label $i$. Nous allons ensuite calculer avec `y_test` la proportion d'erreur que notre algorithme a fait. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On donne la fonction `distance` qui, étant données 2 images (sous forme de vecteurs), renvoie la distance entre ces deux images (au sens de la distance euclidienne)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(I1,I2):\n",
    "    return sqrt(sum((I1-I2)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Prédire à partir de `X_train` et `y_train`, les labels des images de `X_test` en utilisant l'agorithme du plus proche voisin décrit plus haut. Stocker ces prédictions dans un vecteur `y_pred`.\n",
    "\n",
    "Pour pouvoir comparer par la suite des temps d'exécution, effectuez la commande `t1=time()` avant le début de l'algorithme, et `t2=time()` après la fin de l'algorithme. On pourra alors afficher le temps nécessaire à l'exécution de l'algorithme en faisant `print(t2-t1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import * # permet de calculer les temps d'exécution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Quel est le pourcentage de bonnes classifications ? L'algorithme est-il plus efficace pour détecter C. Powel ou G. W. Bush ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réduction de la dimension**\n",
    "\n",
    "Les images sont représentées par des points dans un espace de dimension 2914 (nombre de pixels).\n",
    "Cependant, les visages possèdent une structure bien particulière (deux yeux, une bouche, un nez, une forme ovoïde).\n",
    "Nous devrions pouvoir trouver un sous-espace de dimension $D<2914$ dans lequel nous puissions représenter fidèlement\n",
    "ces visages. Pour trouver ce sous-espace nous allons réaliser une ACP.\n",
    "\n",
    "Cette réduction de la dimesion va nous permettre :\n",
    "- d'économiser de l'espace pour le stockage des données;\n",
    "- de gagner en temps de calcul pour la reconnaissance de visages;\n",
    "- d'améliorer en moyenne le pourcentage de bonne classification.\n",
    "\n",
    "Le dernier point peut paraitre surprenant puisque que l'on s'attendrait à perdre de l'information en diminuant la dimension de représentation des images. Cependant, toutes les informations de l'image ne sont pas pertinentes pour effectuer la classification des visages (par exemple l'arrière plan). Le fait de ne retenir que les  variables qui contiennent le plus de variance (ici synonyme d'information) permet d'éliminer une partie ce bruit. \n",
    "\n",
    "On utilise ici la fonction `acp` écrite précédemment pour calculer les valeurs principales, les vecteurs principaux et les composantes principales des images de `X_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val, P, C = acp(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Déterminez le nombre $D$ de valeurs propres nécessaires pour expliquer 95% de la variance des images. Et pour expliquer 90% de la variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Nous allons maintenant projeter les images dans l'espace généré par les $D$ premiers vecteurs principaux (où $D$ a été déterminé à la question précédente).\n",
    " \n",
    " **Question 4.** Définir la matrice `C_train` contenant les $D$ premières composantes principales pour `X_train`. Définir également `C_test` contenant les coordonnées des images de `X_test` dans ce nouvel espace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** Appliquez l'algorithme du plus proche voisin avec ces nouvelles coordonnées. Déterminez le temps d'exécution et comparez avec la question 1. Calculez le pourcentage de bonnes classifications et comparez avec la question 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
